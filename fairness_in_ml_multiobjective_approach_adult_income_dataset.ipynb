{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 13:19:27.017900: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.selection.tournament import TournamentSelection\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.termination import get_termination\n",
    "\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(Path.cwd())\n",
    "file_path = path / 'dataset' / 'adult_income.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "                'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "                'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "df = pd.read_csv(file_path, names=column_names, sep=',', skipinitialspace=True)\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "\n",
    "categorical_columns = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "continuous_columns = [col for col in X.columns if col not in categorical_columns]\n",
    "\n",
    "X = pd.get_dummies(X, columns=categorical_columns)\n",
    "one_hot_encoded_columns = [col for col in X.columns if col not in continuous_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_continuous = pd.DataFrame(scaler.fit_transform(X[continuous_columns]), index=X.index, columns=continuous_columns)\n",
    "X = X_continuous.join(X[one_hot_encoded_columns])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_calculator(protected_attribute_list, fairness_metric, X, y, y_pred):\n",
    "    fairness_dictionary = {}\n",
    "\n",
    "    for protected_attribute in protected_attribute_list:\n",
    "        protected_attribute_index = X.columns.get_loc(protected_attribute)\n",
    "        subset_y = []\n",
    "        subset_y_pred = []\n",
    "        indices = X.index[X.iloc[:, protected_attribute_index] == 1].to_list() \n",
    "        \n",
    "        for i in indices:\n",
    "            subset_y.append(y[i])\n",
    "            subset_y_pred.append(y_pred[i])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(subset_y, subset_y_pred).ravel()\n",
    "        \n",
    "        if fairness_metric == 'Equal Opportunity':\n",
    "            tpr = tp / (tp + fn)\n",
    "            fairness = tpr\n",
    "        elif fairness_metric == 'Equalized Odds':\n",
    "            fpr = fp / (fp + tn)\n",
    "            fairness = fpr\n",
    "        elif fairness_metric == 'Disparate Impact':\n",
    "            n = tn + fp + fn + tp\n",
    "            ppp = (tp + fp / n)\n",
    "            fairness = ppp\n",
    "      \n",
    "        fairness_dictionary[protected_attribute] = fairness\n",
    "\n",
    "    fairness_difference = abs(fairness_dictionary[protected_attribute_list[0]] - fairness_dictionary[protected_attribute_list[1]])\n",
    "    return fairness_difference\n",
    "\n",
    "def lexicographic_tournament(pop, P, threshold, priority, **kwargs):\n",
    "    n_tournaments, n_competitors = P.shape\n",
    "    if priority == 1:\n",
    "        objective_1_index = 0\n",
    "        objective_2_index = 1\n",
    "    elif priority == 2:\n",
    "        objective_1_index = 1\n",
    "        objective_2_index = 0\n",
    "    else:\n",
    "        print('ERROR')\n",
    "\n",
    "    if n_competitors != 2:\n",
    "        raise Exception(\"Only pressure=2 allowed for lexicographic tournament!\")\n",
    "\n",
    "    S = np.full(n_tournaments, -1, dtype=int)\n",
    "\n",
    "    for i in range(n_tournaments):\n",
    "        x, y = P[i]\n",
    "\n",
    "        a_x = pop[x].F[objective_1_index]\n",
    "        a_y = pop[y].F[objective_1_index]\n",
    "        t_a = threshold[objective_1_index]\n",
    "\n",
    "        if abs(a_x - a_y) > t_a:\n",
    "            S[i] = x if a_x < a_y else y\n",
    "\n",
    "        else:\n",
    "            b_x = pop[x].F[objective_2_index]\n",
    "            b_y = pop[y].F[objective_2_index]\n",
    "            t_b = threshold[objective_2_index]\n",
    "\n",
    "            if abs(b_x - b_y) < t_b:\n",
    "                S[i] = x if b_x < b_y else y\n",
    "\n",
    "            else:\n",
    "                S[i] = x if a_x < a_y else y\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(lr, protected_attribute_list, fairness_metric):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=float(lr)), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_pred = pd.Series(y_pred, index=X_train.index)\n",
    "\n",
    "    fairness_difference = fairness_calculator(protected_attribute_list, fairness_metric, X_train, y_train, y_pred)\n",
    "\n",
    "    return accuracy, fairness_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateOptimizationProblem(Problem):\n",
    "    def __init__(self, protected_attribute_list, fairness_metric):\n",
    "        super().__init__(n_var=1, n_obj=2, n_constr=0, xl=0.0001, xu=0.1)\n",
    "        self.protected_attribute_list = protected_attribute_list\n",
    "        self.fairness_metric = fairness_metric\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        results = np.array([train_and_evaluate(lr, self.protected_attribute_list, self.fairness_metric) for lr in x])\n",
    "        negative_accuracy = -results[:, 0]\n",
    "        fairness_diference = results[:, 1]\n",
    "        out[\"F\"] = np.column_stack([negative_accuracy, fairness_diference])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting combination: 25\n",
      "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m755/755\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning, module='keras')\n",
    "population_size = 50\n",
    "number_generations = 10\n",
    "priority = 1 #accuracy\n",
    " \n",
    "fairness_metric_vector = ['Equal Opportunity', 'Equalized Odds', 'Disparate Impact']\n",
    "protected_attribute_vector = ['Sex', 'Race']\n",
    "threshold = [1e-3, 1e-1, 10]\n",
    "threshold_vector = list(itertools.product(threshold, threshold))\n",
    "results_dictionary = {}\n",
    "\n",
    "complete_combinations = list(itertools.product(fairness_metric_vector, protected_attribute_vector, threshold_vector))\n",
    "\n",
    "start = 25 #state\n",
    "for index in range(start, len(complete_combinations)):\n",
    "    print (f'Starting combination: {index}')\n",
    "\n",
    "    combination = complete_combinations[index]\n",
    "    fairness_metric = combination[0]\n",
    "    protected_attribute = combination[1]\n",
    "    threshold = combination[2]\n",
    "\n",
    "    if protected_attribute == 'Sex':\n",
    "        protected_attribute_list = ['sex_Male', 'sex_Female'] \n",
    "    elif protected_attribute == 'Race':\n",
    "        protected_attribute_list = ['race_White', 'race_Black']\n",
    "    else:\n",
    "        print('ERROR')\n",
    "    \n",
    "    selection = TournamentSelection(pressure=2, func_comp=lambda pop, P, **kwargs: lexicographic_tournament(pop, P, threshold, priority, **kwargs))\n",
    "    problem = LearningRateOptimizationProblem(protected_attribute_list=protected_attribute_list, fairness_metric=fairness_metric)\n",
    "    algorithm = NSGA2(pop_size=population_size, eliminate_duplicates=True, selection=selection)\n",
    "    \n",
    "    res = minimize(problem,\n",
    "                algorithm,\n",
    "                ('n_gen', number_generations),\n",
    "                seed=1,\n",
    "                verbose=True)\n",
    "\n",
    "    solutions = res.F.tolist()\n",
    "    learning_rates = res.X.tolist()\n",
    "\n",
    "    title = f'Pareto Front between negative accuracy and {fairness_metric} Difference regarding {protected_attribute} for threshold {threshold}'\n",
    "    xlabel = 'Negative accuracy'\n",
    "    ylabel = f'{fairness_metric} Difference regarding {protected_attribute}'\n",
    "    name = f'{fairness_metric}_{protected_attribute}_{str(threshold)}'\n",
    "\n",
    "    results_dictionary[name] = {\n",
    "        'priority': priority,\n",
    "        'population size': population_size,\n",
    "        'number generations': number_generations,\n",
    "\n",
    "        'threshold fairness difference': threshold[0],\n",
    "        'threshold negative accuracy': threshold[1],\n",
    "        'fairness metric': fairness_metric,\n",
    "        'protected attribute': protected_attribute,\n",
    "        \n",
    "        'solutions': solutions,\n",
    "        'learning rate': learning_rates\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(results_dictionary).T \n",
    "    df.to_excel('results.xlsx', index=True)\n",
    "\n",
    "    print(\"Pareto front solutions (Fairness, Negative Accuracy):\")\n",
    "    for f in solutions:\n",
    "        print(f)\n",
    "    print(\"Corresponding learning rates:\")\n",
    "    for x in learning_rates:\n",
    "        print(x)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(res.F[:, 0], res.F[:, 1], c='blue', marker='o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    file_out = path / 'images' / 'adult_income_dataset' / f'{name}.png'\n",
    "    plt.savefig(file_out, dpi=300)\n",
    "    plt.show()\n",
    "    print (f'Finishing combination: {index}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
